{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***This cheatsheet is prepared for instant usage and imminent easy findings for pandas and relevant tools for importing data. Personal requirements always differs according to the levels. This cheatsheat is designed for common requirements and widely checked codes. Jupyter notebook version 5.7.4 is used.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T18:08:12.904323Z",
     "start_time": "2019-01-05T18:08:12.900773Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np  # I prefer to add numpy library. Suggestion\n",
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T18:27:28.672652Z",
     "start_time": "2019-01-05T18:27:27.596937Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pandas also provides a utility function, pd.show_versions(), which reports the version of its dependencies as well:\n",
    "import pandas as pd\n",
    "print(pd.show_versions(as_json=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-05T19:07:36.114358Z",
     "start_time": "2019-01-05T19:07:34.911237Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assign the filename: file\n",
    "file = '../_world/maritime_boundaries.csv'# Add URL in ' ' or location of the file in ''\n",
    "\n",
    "# Read the whole file into a DataFrame: df\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# Read the first 5 rows of the file into a DataFrame: df\n",
    "df = pd.read_csv(file, nrows=5, header=None)\n",
    "\n",
    "# Print the head of the DataFrame df\n",
    "df.head()\n",
    " \n",
    "# Print the datatype of df\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a file: file\n",
    " \n",
    "filename = 'taras_bulba.txt' \n",
    "file = open(filename, mode='r') # 'r' is to read, 'w' is to write\n",
    "# you may enter '_.text' directly to filename position instead of assigning filename.\n",
    "file = open('taras_bulba.txt', mode='r') # 'r' is to read, 'w' is to write\n",
    "\n",
    "# Print it\n",
    "print(file.read())\n",
    "\n",
    "# Check whether file is closed\n",
    "print(file.closed)\n",
    "\n",
    "# Close file\n",
    "file.close()\n",
    "\n",
    "# Check whether file is closed\n",
    "print(file.closed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read & print the whole text\n",
    "with open('taras_bulba.txt') as file:\n",
    "    print(file.read())\n",
    "\n",
    "# Read & print the first 3 lines   \n",
    "with open('taras_bulba.txt') as file:\n",
    "    print(file.readline())\n",
    "    print(file.readline())\n",
    "    print(file.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T18:58:31.630034Z",
     "start_time": "2019-01-07T18:58:31.590345Z"
    }
   },
   "source": [
    "# Importing flat files using NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assign the filename: file\n",
    "file = 'computational_maths.txt'\n",
    "\n",
    "# Load the data: df\n",
    "df = np.loadtxt(file, delimiter=',')\n",
    "\n",
    "# Print df\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# working-with-mixed-datatypes by using NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(np.genfromtxt()can handle the datasets which have different datatypes\n",
    "in different columns; one column may contain strings and another floats.\n",
    "dtype=None to arguments will figure out what types each column should be.)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "data = np.genfromtxt('../_datasets/titanic.csv', delimiter=',', names=True, dtype=None)\n",
    "\n",
    "print(np.shape(data))\n",
    "\n",
    "print(data['Fare'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Excel Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Assign spreadsheet filename: file\n",
    "file = '../_datasets/battledeath.xlsx'\n",
    "\n",
    "# Load spreadsheet: xl\n",
    "xl = pd.ExcelFile(file)\n",
    "\n",
    "# Parse the first sheet and rename the columns: df1\n",
    "df1 = xl.parse(0, skiprows=[0], names=['Country', 'AAM due to War (2002)'])\n",
    "\n",
    "# Print the head of the DataFrame df1\n",
    "print(df1.head())\n",
    "\n",
    "# Parse the first column of the second sheet and rename the column: df2\n",
    "df2 = xl.parse(0, parse_cols=[0], skiprows=[0], names=['Country'])\n",
    "\n",
    "# Print the head of the DataFrame df2\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing SAS files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Import sas7bdat package\n",
    "from sas7bdat import SAS7BDAT\n",
    "\n",
    "# Save file to a DataFrame: df_sas\n",
    "with SAS7BDAT('../_datasets/sales.sas7bdat') as file:\n",
    "    df_sas = file.to_data_frame()\n",
    "\n",
    "# Print head of DataFrame\n",
    "print(df_sas.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Stata files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Stata file into a pandas DataFrame: df\n",
    "df = pd.read_stata('../_datasets/disarea.dta')\n",
    "\n",
    "# Print the head of the DataFrame df\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T19:01:55.794949Z",
     "start_time": "2019-01-07T19:01:55.792757Z"
    }
   },
   "source": [
    "# Importing HDF5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Assign filename: file\n",
    "file = '../_datasets/LIGO_data.hdf5'\n",
    "\n",
    "# Load file: data\n",
    "data = h5py.File(file, 'r')\n",
    "\n",
    "# Get the HDF5 group: group\n",
    "group = data['strain']\n",
    "\n",
    "# Check out keys of group\n",
    "for key in group.keys():\n",
    "    print(key)\n",
    "\n",
    "# Set variable equal to time series data: strain\n",
    "strain = data['strain']['Strain'].value\n",
    "\n",
    "# Set number of time points to sample: num_samples\n",
    "num_samples = 10000\n",
    "\n",
    "# Set time vector\n",
    "time = np.arange(0, 1, 1/num_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import sheets from excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assign spreadsheet filename: file\n",
    "file = '../_datasets/customer.xlsx'\n",
    "\n",
    "# Load spreadsheet: xl\n",
    "xl = pd.ExcelFile(file)\n",
    "\n",
    "# Load a sheet into a DataFrame by name: df1\n",
    "df1 = xl.parse('2012')\n",
    "\n",
    "# Print the head of the DataFrame df1\n",
    "print(df1.head())\n",
    "\n",
    "# Load a sheet into a DataFrame by index: df2\n",
    "df2 = xl.parse(0)\n",
    "\n",
    "# Print the head of the DataFrame df2\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Open pickle file and load data: d\n",
    "with open('data.pkl', 'rb') as file:\n",
    "    d = pickle.load(file)\n",
    "\n",
    "# Print d\n",
    "print(d)\n",
    "\n",
    "# Print datatype of d\n",
    "print(type(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing a .mat file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "# Load MATLAB file: mat\n",
    "mat = scipy.io.loadmat('../_datasets/albeck_gene_expression.mat')\n",
    "\n",
    "# Print the datatype type of mat\n",
    "print(type(mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing flat files from the WEB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file: url\n",
    "url = 'https://s3.amazonaws.com/assets.datacamp.com/production/course_1606/datasets/winequality-red.csv'\n",
    "\n",
    "# Save file locally\n",
    "urlretrieve(url, 'winequality-red.csv')\n",
    "\n",
    "# Read file into a DataFrame and print its head\n",
    "df = pd.read_csv('winequality-red.csv', sep=';')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing files with GET requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Specify the url: url\n",
    "url = \"http://www.datacamp.com/teach/documentation\"\n",
    "\n",
    "# Packages the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Extract the response: text\n",
    "text = r.text\n",
    "\n",
    "# Print the html\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET requests using urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen, Request\n",
    "\n",
    "# Specify the url\n",
    "url = \"http://www.wikipedia.org\"\n",
    "\n",
    "# This packages the request: request\n",
    "request = Request(url)\n",
    "\n",
    "# Sends the request and catches the response: response\n",
    "response = urlopen(request)\n",
    "\n",
    "# Print the datatype of response\n",
    "print(type(response))\n",
    "\n",
    "# Be polite and close the response!\n",
    "response.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Web Page as Data with BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Specify url\n",
    "url = 'https://www.python.org/~guido/'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Extracts the response as html: html_doc\n",
    "html_doc = r.text\n",
    "\n",
    "# create a BeautifulSoup object from the HTML: soup\n",
    "soup = BeautifulSoup(html_doc)\n",
    "\n",
    "# Print the title of Guido's webpage\n",
    "print(soup.title)\n",
    "\n",
    "# Find all 'a' tags (which define hyperlinks): a_tags\n",
    "a_tags = soup.find_all('a')\n",
    "\n",
    "# Print the URLs to the shell\n",
    "for link in a_tags:\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Specify url: url\n",
    "url = 'https://www.python.org/~guido/'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Extract the response as html: html_doc\n",
    "html_doc = r.text\n",
    "\n",
    "# Create a BeautifulSoup object from the HTML: soup\n",
    "soup = BeautifulSoup(html_doc)\n",
    "\n",
    "# Get the title of Guido's webpage: guido_title\n",
    "guido_title = soup.title\n",
    "\n",
    "# Print the title of Guido's webpage to the shell\n",
    "print(guido_title)\n",
    "\n",
    "# Get Guido's text: guido_text\n",
    "guido_text = soup.get_text()\n",
    "\n",
    "# Print Guido's text to the shell\n",
    "print(guido_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading JSONs in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T19:54:40.989701Z",
     "start_time": "2019-01-07T19:54:40.963856Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('snakes.json', 'r') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "type(json_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting to an API in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = 'http://www.omdbapi.com/?t=hackers'\n",
    "r = requests.get(url)\n",
    "json_data = r.json()\n",
    "for key, value in json_data.items():\n",
    "    print(key + ':', value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy, json\n",
    "\n",
    "access_token = \"...\"\n",
    "access_token_secret = \"...\"\n",
    "consumer_key = \"...\"\n",
    "consumer_secret = \"...\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import json\n",
    "\n",
    "class MyStreamListener(tweepy.StreamListener):\n",
    "    def __init__(self, api=None):\n",
    "        super(MyStreamListener, self).__init__()\n",
    "        self.num_tweets = 0\n",
    "        self.file = open(\"tweets.txt\", \"w\")\n",
    "    def on_status(self, status):\n",
    "        tweet = status._json\n",
    "        self.file.write(json.dumps(tweet) + '\\n')\n",
    "        tweet_list.append(status)\n",
    "        self.num_tweets += 1\n",
    "        if self.num_tweets < 100:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        self.file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Stream listener\n",
    "l = MyStreamListener()\n",
    "\n",
    "# Create you Stream object with authentication\n",
    "stream = tweepy.Stream(auth, l)\n",
    "\n",
    "\n",
    "# Filter Twitter Streams to capture data by the keywords:\n",
    "stream.filter(track=['clinton', 'trump', 'sanders', 'cruz'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
